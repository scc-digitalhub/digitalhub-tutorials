{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07fbf4b6",
   "metadata": {},
   "source": [
    "# DBT Data Transformation Tutorial with DigitalHub\n",
    "\n",
    "This notebook demonstrates how to build a data transformation pipeline using DBT (Data Build Tool) with the DigitalHub SDK. We'll work with employee data, apply SQL transformations, and orchestrate the process through a workflow.\n",
    "\n",
    "## Overview\n",
    "- **Extract**: Load employee data from a CSV source\n",
    "- **Transform**: Use DBT to filter and process the data with SQL\n",
    "- **Orchestrate**: Create a workflow pipeline to automate the transformation process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c080f0c",
   "metadata": {},
   "source": [
    "## Setup and Function Definitions\n",
    "\n",
    "First, we'll create the necessary directory structure and define our SQL transformation that will be used by DBT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c53559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path(\"src\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f5d087",
   "metadata": {},
   "source": [
    "### SQL Transformation Definition\n",
    "\n",
    "This cell creates our DBT SQL transformation. The SQL query will:\n",
    "\n",
    "- Reference the input employees table using DBT's `{{ ref('employees') }}` syntax\n",
    "- Filter employees by department ID '50' \n",
    "- Return all columns for employees in that specific department\n",
    "\n",
    "The transformation is designed to work with DBT's templating system and will be executed as part of our data pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3289c6c8",
   "metadata": {},
   "source": [
    "## Project Initialization\n",
    "\n",
    "Now we'll initialize our DigitalHub project using consistent naming with other tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4c8f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitalhub as dh\n",
    "\n",
    "p_name = \"tutorial-project\"\n",
    "project = dh.get_or_create_project(p_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75266e1a",
   "metadata": {},
   "source": [
    "## Data Source Setup\n",
    "\n",
    "We'll create a data item that points to employee data. This dataset contains employee information including department assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485f9067",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://gist.githubusercontent.com/kevin336/acbb2271e66c10a5b73aacf82ca82784/raw/e38afe62e088394d61ed30884dd50a6826eee0a8/employees.csv\"\n",
    "di = project.new_dataitem(name=\"employees-data\", kind=\"table\", path=url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deb3b1e",
   "metadata": {},
   "source": [
    "## Data Transformation with DBT\n",
    "\n",
    "Now we'll create and execute our DBT transformation function. This will filter the employee data to show only employees in department '50'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae29870",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "WITH tab AS (\n",
    "    SELECT  *\n",
    "    FROM    {{ ref('employees') }}\n",
    ")\n",
    "SELECT  *\n",
    "FROM    tab\n",
    "WHERE   tab.\"DEPARTMENT_ID\" = '50'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73cb401",
   "metadata": {},
   "outputs": [],
   "source": [
    "function = project.new_function(name=\"transform-employees\", kind=\"dbt\", code=sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04d5ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = function.run(\n",
    "    \"transform\",\n",
    "    inputs={\"employees\": di.key},\n",
    "    outputs={\"output_table\": \"department-50\"},\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99f5de9",
   "metadata": {},
   "source": [
    "Let's examine the transformed data - employees from department 50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bc2933",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.output(\"department-50\").as_df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f2409",
   "metadata": {},
   "source": [
    "## Pipeline Orchestration\n",
    "\n",
    "Now let's create a workflow that orchestrates the DBT transformation. This pipeline uses Hera (Argo Workflows) to define the execution flow for our data transformation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166ea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"src/pipeline.py\"\n",
    "from hera.workflows import Workflow, DAG, Parameter\n",
    "from digitalhub_runtime_hera.dsl import step\n",
    "\n",
    "\n",
    "def pipeline():\n",
    "    with Workflow(entrypoint=\"dag\", arguments=Parameter(name=\"employees\")) as w:\n",
    "        with DAG(name=\"dag\"):\n",
    "            A = step(template={\"action\":\"transform\",\n",
    "                               \"inputs\": {\"employees\": \"{{workflow.parameters.employees}}\"},\n",
    "                               \"outputs\": {\"output_table\": \"department-50\"}},\n",
    "                     function=\"transform-employees\")\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56ee2b0",
   "metadata": {},
   "source": [
    "### Execute the Complete Pipeline\n",
    "\n",
    "Finally, let's create and execute our DBT transformation pipeline workflow. This will run the transformation in an automated, orchestrated manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = project.new_workflow(\n",
    "    name=\"dbt-pipeline\", kind=\"hera\", code_src=\"src/pipeline.py\", handler=\"pipeline\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217878a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.run(\"build\", wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd499f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_run = workflow.run(\"pipeline\", parameters={\"employees\": di.key}, wait=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
